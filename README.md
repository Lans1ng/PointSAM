# PointSAM: Pointly-Supervised Segment Anything Model for Remote Sensing Images
<p align="center">
    <img src="https://i.imgur.com/waxVImv.png" alt="Oryx Video-ChatGPT">
</p>

[![paper](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2409.13401)
---

## ğŸ“¢ Latest Updates
- **20 Sep 2024**: The arXiv version is released [here](https://arxiv.org/abs/2409.13401).
---

 The code will be released soon. 

## Overview
<div align="center">
  <img width="700" src="assets/overview.jpg"/>
</div>

## ğŸ® Getting Started
### 1.Install Environment
```bash
conda create --name pointsam python=3.10
conda activate pointsam

pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu118
git clone https://github.com/Lans1ng/PointSAM.git
cd PointSAM
pip install -r requirements.txt

cd segment_anything_2
pip install -e .
cd ..
```

### 2.Prepare Dataset 

#### WHU Building Dataset

- Dataset download address: [WHU Building Dataset](https://aistudio.baidu.com/datasetdetail/56502)ã€‚

- For converting semantic label to instance label, you can refer to corresponding [conversion script](https://github.com/KyanChen/RSPrompter/blob/release/tools/rsprompter/whu2coco.py).

#### HRSID Dataset

- Dataset download address: [HRSID Dataset](https://github.com/chaozhong2010/HRSID).

#### NWPU VHR-10 Dataset

- Dataset download address: [NWPU VHR-10 Dataset](https://aistudio.baidu.com/datasetdetail/52812).

- Instance label download address: [NWPU VHR-10 Instance Label](https://github.com/chaozhong2010/VHR-10_dataset_coco).



```
data 
â”œâ”€â”€ WHU
â”‚    â”œâ”€â”€ annotations
â”‚    â”‚   â”œâ”€â”€ WHU_building_train.json
â”‚    â”‚   â”œâ”€â”€ WHU_building_test.json
â”‚    â”‚   â””â”€â”€ WHU_building_val.json
â”‚    â””â”€â”€ images
â”‚        â”œâ”€â”€ train
â”‚        â”‚    â”œâ”€â”€ image
â”‚        â”‚    â””â”€â”€ label
â”‚        â”œâ”€â”€ val
â”‚        â”‚    â”œâ”€â”€ image
â”‚        â”‚    â””â”€â”€ label
â”‚        â””â”€â”€ test
â”‚             â”œâ”€â”€ image
â”‚             â””â”€â”€ label
â”œâ”€â”€ HRSID
â”‚    â”œâ”€â”€ Annotations
â”‚    â”‚   â”œâ”€â”€ all
â”‚    â”‚   â”œâ”€â”€ inshore
â”‚    â”‚   â”‚      â”œâ”€â”€ inshore_test.json
â”‚    â”‚   â”‚      â””â”€â”€ inshore_train.json       
â”‚    â”‚   â””â”€â”€ offshore
â”‚    â””â”€â”€ JPEGImages
â””â”€â”€ NWPU
     â”œâ”€â”€ Annotations
     â”‚   â”œâ”€â”€ NWPU_instnaces_train.json
     â”‚   â””â”€â”€ NWPU_instnaces_val.json
     â””â”€â”€ images

```

## ğŸ’¡ Acknowledgement

- [wesam](https://github.com/zhang-haojie/wesam)
- [OWOD](https://github.com/JosephKJ/OWOD)
- [RSPrompter](https://github.com/KyanChen/RSPrompter)


## ğŸ–Šï¸ Citation

If you find this project useful in your research, please consider cite:

```BibTeX
@article{liu2024pointsam,
  title={PointSAM: Pointly-Supervised Segment Anything Model for Remote Sensing Images},
  author={Liu, Nanqing and Xu, Xun and Su, Yongyi and Zhang, Haojie and Li, Heng-Chao},
  journal={arXiv preprint arXiv:2409.13401},
  year={2024}
}
```
